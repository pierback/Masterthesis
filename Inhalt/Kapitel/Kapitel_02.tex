\chapter{Stand der Technik}
\label{kap:Kapitel02}
%\nocite{*} << blendet alle Referenzen ein, auch wenn diese nicht im Text zitiert wurden
%
       
%
\section{Blockchain}
\subsection{Funktionsweise \& Konzepte}
Damit das Verständnis für die Blockchain Technologie geschaffen werden kann, sollte zuerst die darunter liegende Technologie betrachtet werden. 
So wird der Begriff der Blockchain oft auch mit dem des \textit{distributed ledger} gleichgesetzt. Ein \textit{distributed ledger} ist eine verteilte Datenbank, welche im Kontext einer Blockchain auch als verteiltes Konto bzw. dezentral geführtes Kontobuch \cite{DL:bafin} verstanden wird, in welchem jegliche Transaktionen abgespeichert werden.\\
Allerdings ist diese Pa­ri­tät nicht vollkommen korrekt, denn eine Blockchain ist nur ein spezieller Typus eines \textit{distributed ledgers}. Im Allgemeinen kann dieser nämlich neben Transaktionen, auch aus weiteren Daten bestehen, wohingegen bei einer Blockchain die Blöcke stets Transaktionen beinhalten. \\
Somit stellt ein \textit{distributed ledger} die technologische Grundlage aller virtuellen Währungen dar und ist dadurch auch einer der Hauptgründe weshalb Kryptowährungen auf einer Blockchain basieren.\\\\
Grundsätzlich steht Blockchain für eine Verkettung von geordneten Blöcken, welche in sich eine oder mehrere Transaktionen beinhalten. 
Zu den Transaktionsdaten wird zudem ein Hashwert des Vorgängerblocks und ein Zeitstempel in einem Block abgespeichert. Erst aufgrund der Berücksichtigung des Hashwerts des vorherigen Blocks werden die Blöcke miteinander verknüpft und bilden somit eine chronologisch geordnete Kette \cite{MasteringBlockchain}.\\
Eine weitere Beschaffenheit einer Blockchain ist die Dezentralität durch das aufgespannte \textit{Peer-to-Peer} Netzwerk. Der Vorteil dieser Topologie besteht in der Vakanz eines zentralen Knotens (\textit{Node}), der für das Abspeichern und Bereitstellen aller bestehenden Daten eines Netzwerks zuständig ist. Jeder Knoten in einem solchem Netzwerk ist sowohl Sender als auch Empfänger, sodass alle Teilnehmer eine Kopie des Datenbestandes besitzen, was einen \quotes{Single Point of Failure} völlig ausschließt. Aus diesem Grund sind Daten einer Blockchain nie nur bei einem Knoten abgespeichert, sondern sämtliche Nodes besitzen eine Kopie der aktuellen Blockchain.\\\\
Welche Daten schließlich auf die Blockchain geschrieben werden dürfen oder genauer gesagt ob eine Transaktion durchgeführt werden darf, erfolgt stets in Anbetracht des Konsens aller Parteien im Netzwerk. Diese Eigenschaft wird als \textit{distributed consensus} bezeichnet und ist das Fundament einer jeden Blockchain. Durch die Partizipation eines jeden Teilnehmers in die Entscheidungsfindung, wird die Notwendigkeit einer zentralen Entscheidungsinstanz obsolet. \\
Damit löst die Blockchain folgendes Gedankenexperiment von Lamport aus dem Jahr 1982. Eine Gruppe an byzantinischen Generälen, die jeweils verschiedene Teile der byzantinischen Armee befehligen, planen einen Angriff auf eine Stadt. Dieser resultiert allerdings nur in einem Sieg, wenn alle gemeinsam angreifen. Der einzige Weg der Interkommunikation und Koordination ist via Boten. Somit entsteht eine Problematik, sollten sich ein oder mehrere Verräter unter den Generälen befinden und falsche Informationen streuen.\\
Aus diesem Grund bedarf es einem Mechanismus der es erlaubt, trotz Falschinformationen durch potentielle Verräter, einen Konsens unter den Generälen bezüglich eines gemeinsamen Angriffs zu schaffen. \\
Analog zur Blockchain entsprechen die Generäle den Knoten im Netzwerk, die Verräter sind \quotes{bösartige} (malicious) Knoten und die Boten sind die Kommunikationskanäle zwischen den Knoten.\\
Gelöst wurde diese Problematik durch die Publikation des \textit{Practical Byzantine Fault Tolerance (PBFT)} Algorithmus (1999, Castro und Liskov), welcher nach einer bestimmten Anzahl an Nachrichten mit gleichem signierten Inhalt einen Konsens unter allen Knoten herstellt \cite{MasteringBlockchain}.\\ 
Der Mechanismus, dessen Zuständigkeitsbereich das Erzielen des Konsens betrifft, ist je nach Implementierung des Blockchainprotokolls unterschiedlich. Eine populäre Methodik, welche unter anderem von Bitcoin und Ethereum verwendet wird, ist der \textit{Proof-of-Work (PoW)} Ansatz. Hierbei müssen von den sog. \quotes{Minern} Iterationen an aufwändigen und komplexen Berechnungen (\quotes{Puzzles}) durchgeführt werden, bevor von diesen ein neuer Block zur Kette hinzugefügt werden darf. Erst nach der erfolgreichen Verifikation dieser Puzzles, wird ein neuer Block generiert. Der enorme Aufwand, welcher im ersten Schritt aufgewendet werden muss, sollen das Netzwerk vor Angriffen schützen und somit dessen Sicherheit und Stabilität gewährleisten. \\
Als eine weitere Konsens-Methodik ist \textit{Proof-of-Stake} zu nennen. Hierbei können sich Netzwerkteilnehmer als \quotes{Validators} registrieren lassen und daraufhin einen Block vorschlagen (\quotes{vote}), der als nächstes generiert werden soll. Die Auswahl des nächstens Blocks und somit die Bestätigung des Votes, erfolgt durch eine (pseudo) Zufallsauswahl, welche eine Gewichtung aufgrund des Vermögens (\quotes{stake}) des Teilnehmers in der Blockchain spezifischen Währung erfährt. Dabei ist das Vermögen proportional zum Anteil der Transaktionen die ein Validator bestätigen kann. Dadurch ist es um so wahrscheinlicher, dass ein Teilnehmer einen Block generieren darf, desto höher sein Stake ist. \\
Diese Methodik hat mehrere Vorteile gegenüber \textit{PoW}, der Größte jedoch besteht in der Recheneffizienz. So werden bei \textit{PoW} durch die Berechnung der Puzzles große Mengen an Strom verbraucht, um das Netzwerk letztlich vor Angreifern zu schützen. Dies ist im Hinblick auf \textit{PoS} äußerst ineffizient, da der Schutzmechanismus nicht auf der Erbringung einer gewissen Rechenleistung beruht, sondern ein Validator bei netzwerkwidrigem Verhalten seinen Stake verliert und somit sichergestellt wird, dass alle Teilnehmer im Sinne des Netzwerks agieren \cite{PoS:BCMAG,PoS:EthWiki}. \\\\
Eine weitere Besonderheit einer Blockchain ist die Unveränderbarkeit der Blöcke. So gibt es, im Gegensatz zu den bekannten CRUD-Operationen, welche zur Kommunikation zwischen Client und Server verwendet werden, Daten zu schreiben, zu downloaden, zu löschen und zu editieren, bei einer Blockchain lediglich eine Schreib- und eine Leseoperation. Weswegen im Zusammenspiel mit dem Konsensverfahren, Transaktionen auf einer Blockchain einzig hinzugefügt und gelesen, jedoch nie zu einem späteren Zeitpunkt gelöscht oder editiert werden können. \\
Dabei sind die gespeicherten Daten (unverschlüsselt oder auch verschlüsselt) für alle im Netzwerk einsehbar. Dies bedeutet somit volle Transparenz für jeden User. \\\\ 
Die gerade geschilderten Eigenschaften sind einer jeden Blockchain inhärent. 
Was jedoch erst in neueren Blockchains (Blockchain 2.0) vorzufinden ist, sind die \textit{Smart Contracts} \cite{SC:EconomyOutlook, MasteringBlockchain}.\\
Smart Contracts sind sozusagen Anwendungen die auf einer Blockchain installiert werden können.\\
Diese Programme können z.B. Business Logiken abbilden und ausführen oder auch Verpflichtungen und Vereinbarungen im rechtlichen Sinne durchsetzten, ohne der Notwendigkeit eines Mittelsmanns, welcher das Vertrauen aller beteiligten Parteien inne hat. Diese \quotes{Trust-Komponente} wird durch die Annerkennung des Smart Contracts von allen Parteien übernommen. \\
Das erste Mal in Erscheinung getreten sind Smart Contracts mit der Veröffentlichung der Ethereum Blockchain, welche nun im Anschluss genauer betrachtet wird.

\subsection{Ethereum}
Die Ethereum Blockchain wurde 2015 in Betrieb genommen, mit dem Ziel nicht nur eine Kryptowährung zu schaffen, sondern eine Plattform zu entwickeln, auf der sogenannte \textit{DApps} (Decentralized Apps) betrieben werden können.
So wird Ethereum im Vergleich zu Bitcoin auch als Blockchain 2.0 bezeichnet. Dies ist der Tatsache geschuldet, dass es eben nicht nur eine Kryptowährung umfasst, sondern aufgrund der Smart Contracts möglich ist Software auf einer Blockchain zu installieren. \\
Als Ethereum wird genauer genommen das Protokoll tituliert, welches die Blockchain implementiert. Die Kryptowährung die auf der Blockchain basiert, wird als \textit{Ether} bezeichnet und fungiert zudem als Zahlungsmittel im Kontext der Smart Contracts. So ist das Bestreben der Gründer nicht eine weitere Kryptowährung zu schaffen, sondern einen Art \quotes{Supercomputer}, welcher permanent online ist und aus Millionen von Computern im Netzwerk besteht, die ihre Rechenleistung zur Verfügung stellen und als Gegenleistung in Form von Ether vergütet werden \cite{BitcoinEthNCo}. \\
Dabei können zwar, wie bei einer Kryptowährung, Transaktionen durchgeführt und Ether von einem Konto auf ein anderes transferiert werden. Jedoch liegt der eigentliche Fokus auf den Smart Contracts und den DApps.\\
Dazu wurde die \textit{EVM (Ethereum Virtual Machine)} entwickelt, in der letztlich die Smart Contracts bzw. DApps gehostet und ausgeführt werden. Dabei stellt die Virtual Machine eine Abstraktionsebene zur physischen Schicht der Blockchain dar. Sie ermöglicht den Smart Contracts, Daten auf die Blockchain zu speichern und bietet diesen gleichzeitig eine Laufzeitumgebung, in der die Anwendungen ausgeführt werden können.\\
Die Implementierung der Smart Contracts erfolgt stets in der eigens entwickelten Programmiersprache \textit{Solidity}. Diese folgt dem Prinzip der Objekt Orientierung, ist der Sprache Javascript angelehnt und zudem Turing-Vollständig, was im Bezug auf die Entwicklung von Apps eine hohe Bandbreite an Anwendungsfällen eröffnet. \\
Damit die Funktionen der Smart Contracts überhaupt genutzt werden können, muss einem jedem Methodenaufruf respektive jeder Transaktion Ether - im Kontext der Smart Contracts als \textit{Gas} bezeichnet - mitgegeben werden, um die Miner für ihre zur Verfügung gestellte Rechenleistung zu entlohnen. Das bedeutet, um Daten auf die Blockchain zu speichern, wird je nach Transaktion eine bestimmte Menge an Gas benötigt, welches im Endeffekt den Minern als Anreiz zur Bereitstellung von Rechenleistung übertragen wird. \\
Zu den DApps gilt es anzumerken, dass diese zwar als vollkommen dezentrale Applikationen gedacht sind, bisherige Umsetzungen jedoch lediglich eine \quotes{semi-dezentrale} Lösung darstellen. \\
So ist das Backend einer DApp, hinsichtlich der Smart Contracts, zwar meist als dezentral zu betrachten. Da es jedoch nicht möglich ist Frontend Templates auf der Ethereum Blockchain zu hosten, sind diese in der Regel immer auf einem Server abgespeichert, wodurch eine DApp nie als vollkommen dezentral angesehen werden kann. \\
Zudem sind, trotz der Turing-Vollständigkeit von \textit{Solidity}, aufwendige Berechnungen und Abbildungen komplexer Business Prozesse infolge der Transaktionskosten nur schwer oder gar nicht zu bewerkstelligen, weswegen diese Logiken gewöhnlich auch auf einen Server ausgelagert werden.\\
In naher Zukunft könnte hierbei ein Umstieg auf IPFS Abhilfe schaffen, indem es an Stelle der Server als Speicherort der Frontend-Logik verwendet wird.  \\\\
Wie das Mining bereits impliziert, basiert der Konsensalgorithmus der Ethereum Blockchain auf dem Proof-of-Work Konzept. Da dieser Ansatz jedoch einige Nachteile mit sich bringt, was Energieeffezienz und Transaktionen pro Sekunde betrifft, wird bereits an der Implementierungd eines Proof-of-Stake Konsensalgorithmus gearbeitet. Eine erste Version wurde am 07.05.2019 im \quotes{Prysm Eth2 Testnet} bereits veröffentlicht \cite{ETH20:PRYSM}. \\\\
Die große Community, der Opensource Ansatz, die Verfügbarkeit von Libraries in verschiedenen Programmiersprachen und Kommandzeilenanwendungen, sowie die Möglichkeit Smart Contracts bzw. DApps auf der Blockchain zu betreiben, sind einer der Hauptgründe, weshalb die Wahl bei dieser Arbeit auf Ethereum gefallen ist.   
\cite{BitcoinEthNCo,DL:bafin,Antonopoulos:2017:MBP:3164842}

\clearpage
\section{Machine Learning}
\subsection{"Uberblick}

Der Fortschritt in der Entwicklung von Machine Learning Algorithmen in den letzten Jahren hat dazu geführt, dass Algorithmen in vielerlei Bereiche des Alltags Einzug gefunden haben. Vor allem im Kontext von Aufgabenstellungen bei denen eine große Menge an Daten vorhanden ist, werden diese Algorithmen zur Extrahierung relevanter Informationen verwendet. \\
Mit dem Anstieg der Digitalisierung entstehen immer mehr Datensätze von solch enormer Größe. Sei es durch die Vernetzung von Geräten und Sensoren im Bereich des IoT oder auch das Sammeln von Nutzerdaten durch Smartphone-Apps, die Intention besteht stets in der Erlangung eines besseren Verständnisess für eine konkrete Problemstellung in der realen Welt. \\
Aufgrund dessen ergeben sich eine Vielzahl an Anwendungsfeldern für Machine Learning Algorithmen.\\
Eines davon fällt unter die Begrifflichkeit des Data Mining's. Hierbei erfolgt eine Entscheidungsfindung durch den Algorithmus anhand von Datenaufzeichnung in einem bestimmten Gebiet. Als Beispiel wäre hier die Analyse von Krankenakten zu nennen, welche zu einem besseren Verständnis von Krankheitsbildern, sowie einer genaueren Diagnose führen soll. \\
Ein weiteres Anwendungsgebiet sind Problemstellungen, deren Lösung nicht durch eine (klassisch) imperativ implementierte Software gefunden werden kann.
Dies ist dann der Fall, wenn die Anwendung aufgrund der enormen Vielzahl an Varianten nicht alle möglichen Status abbilden kann. Zu nennen sind hier die Spracherkennung oder auch das autonome Fahren, welche schlichtweg nur mit Machine Learning realisierbar sind.\\
In die Kategorie des nächsten Gebietes, fällt auch die Problemstellung dieser Arbeit. Es handelt sich um die Personalisierung (\quotes{customization}) von Software-Anwendungen und Services. Dabei wird Machine Learning dazu verwendet, um das Verhalten der User besser zu verstehen. Die gesammelten Nutzerdaten werden analysiert und Präferenzen der User aufgrund ihres \\(Online-)Verhaltens abgeleitet. So werden zum Beispiel im Falle von Facebook oder Google, dadurch gezielt Werbeanzeigen platziert und auf den User abgestimmt. \cite{mlmitchel} \\\\
Somit eignen sich je nach Anwendungsgebiet und Problemstellung unterschiedliche Typen von Machine Learning Algorithmen. 
Eine inhärente Eigenschaft eines Machine Learning Algorithmus ist die Notwendigkeit eines Input \textit{Y} in Form von \textit{Features}. Ein \textit{Feature} ist eine numerische Repräsentation eines Teilaspekts der Inputdaten. Dabei ist die Konkatenation jener auch als \textit{Feature Vektor} bekannt. Machine Learning beschreibt somit die Identifikation von Strukturen und Mustern auf Basis einer Kollektion von \textit{Feature Vektoren} \cite{fteng}. \\\\
Generell lässt sich eine Unterteilung der Machine Learning Algorithmen in drei Typen machen, dabei erfolgt eine Unterscheidung aufgrund der Art des Lernprozesses. \\
Die wohl bekannteste Kategorie ist das Supervised Learning. Algorithmen die unter diesen Teilbereich fallen, haben das Ziel für einen Input \textit{X} einen Output \textit{Y} zu finden. Hierfür wird diesen in der Lernphase ein Datensatz vorgelegt, bei welchem diese Abbildung (\textit{X} $\rightarrow$ \textit{Y}) bereits vorhanden ist und die Algorithmen sich somit Wissen aneignen können. Nach dem erfolgreichen Durchlauf der Lernphase sind die Algorithmen in der Lage bei Eingabe von unbekannten Input-Daten, basierend auf dem angeeigneten Wissen, eine Generalisierung durchzuführen und einen Output \textit{Y} (\textit{Labels}) für \textit{X} zu liefern. \\
Der Nachteil dieser Algorithmen liegt in der Aufbereitung und Bereitstellung dieser Lerndaten, welche in der Regel manuell erstellt werden müssen \cite{Engemann}.\\\\
Im Kontrast dazu ist das Unsupervised Learning zu verstehen. Diese Algorithmen benötigen zum Lernen nur einen Input \textit{X} im Datensatz. Trotz fehlender \textit{Labels} können diese im Datensatz statistische Strukturen aufdecken bzw. ein Modell für diesen Datensatz erarbeiten. Als Beispiele hierfür sind das Clustering (k-Means) der Daten oder die Reduktion (PCA) zu nennen. \cite{Engemann,mlmitchel, Sutton}\\\\
Ein weiterer Lernansatz welcher sich zwischen den beiden eben genannten Kategorien einreiht, trägt die Bezeichnung Reinforcement Learning und wird im nächsten Unterkapitel genauer betrachtet.

\subsection{Reinforcement-Learning}
\label{subsec:rl}
Das folgende Unterkapitel basiert auf der Literatur folgender Quellen: \cite{MultiagentSystems,mlmitchel,Sutton}\\\\
Das Grundprinzip des Reinforcement-Learning besteht darin, bestimmte Situationen auf Aktionen zu projizieren, um dabei den numerischen Reward des Agenten zu maximieren. Diese Aktionen werden dem Agenten jedoch nicht durch eine \quotes{Superviser-Instanz} mitgeteilt, hingegen versucht dieser durch die \quotes{Trial and Error} Methodik herauszufinden, welche Aktion in welchem Zustand  den größten Reward zur Folge hat. Dabei können diese Aktionen nicht nur die Belohnung des Agenten beeinflussen, sondern zudem die Umgebung in der er sich bewegt und dadurch auch den Folgezustand. \\
Dieses Konzept der Reward-Maximierung resultiert in dem Tradeoff zwischen \textit{Exploration} und \textit{Exploitation}. Exploration beschreibt den Versuch mehr Information über die Umgebung zu erlangen, indem die Reward-Maximierung außer Acht gelassen und eine Aktion zufällig ausgewählt wird, mit dem Ziel den bisherigen Reward zu übertreffen. Im Gegenteil dazu spezifiziert Exploitation die Maximierung des Rewards. Hierbei greift der Agent stets auf die, in einem bestimmten Zustand, bestbewertete Aktion zurück.\\
Je nach Algorithmus und Lernproblem variiert dieses Verhältnis, welches durch eine iterative Justierung der Parameter anzupassen gilt. \\
Durch die Wechselwirkung ist es die Aufgabe des Agenten eine Strategie zu finden, die letztlich den maximalen Reward garantiert, indem es sein Verhalten in den jeweiligen Zuständen bereits vorgibt. \\
Dabei gilt es vor allem zu beachten, ob es sich bei dem Lernproblem um ein Deterministisches oder Nichtdeterministisches handelt. Deterministisch bedeutet, es wird stets die gleiche Aktion in einem bestimmten Zustand gewählt, wohingegen nichtdeterministisch lediglich eine Wahrscheinlichkeitsverteilung beschreibt, anhand jener der Agent in einem Zustand entscheidet, welche Aktion auszuwählen ist.\\\\
Im Allgemeinen lassen sich folgende inhärente Eigenschaften an Reinforcement Learning Algorithmen feststellen:
\begin{itemize}
    \item Agent: lernendes System, dessen Ziel es ist seine Belohnung zu maximieren, indem es seine Umgebung wahrnimmt und mittels Aktionen beeinflusst
    \item Umgebung: diese beschreibt Bestandteile außerhalb des lernenden Systems (andere Agenten, Programme, Menschen etc.) und ist entweder von deterministischer oder nichtdeterministischer Natur
    \item Reward: numerischer Wert der die Nützlichkeit einer Aktion im aktuellen Zustand beschreibt und dadurch als direktes Feedback für den Agenten zu sehen ist
    \item Wertfunktion: ist die Akkumulation aller erhaltenen Belohnungen, startend bei einem bestimmten Zustand bis hin zum Ende eines Durchlaufs und stellt somit eine Schätzung bezüglich der Wertigkeit dieses Zustandes dar
    \item Strategie: definiert das Verhalten des Agenten zu einem bestimmten Zeitpunkt bzw. welche Aktionen in welchen Zuständen ausgeführt wird
    \item Umgebungsmodell: ist die Abbildung des Verhaltens der Umgebung, um kommende Zustände und Belohnung vorherzusagen und auf dieser Basis eine geeignete Strategie zu finden
\end{itemize}
Jedoch sind nicht alle Reinforcement Algorithmen gleich, sondern in ihrer Definition und Umsetzung der eben genannten Eigenschaften oftmals sehr unterschiedlich. Eine Kategorisierung wird in der Regel anhand der Berechnung der Wertfunktion durchgeführt, woraus sich drei verschiedene Klassen an Reinforcement Algorithmen ergeben. Diese differieren in der Berechnung der Wertfunktion durch verschiedene Lösungsansätze.\\\\
\newpage
Als erste Kategorie ist die Dynamische Programmierung (DP) zu nennen.
Diese Algorithmen sind mathematisch präzise, benötigen dafür aber ein perfektes Umgebungsmodell, welches bereits die Rewards und Übergangswahrscheinlichkeiten aller Zustände beinhaltet. So beruht die Berechnung der Wertfunktion auf dem \textit{Markow-Entscheidungsproblem} (\textit{MEP} oder auch \textit{MDP} \textit{Markov decision process}). Dieses Modell erlaubt die Erarbeitung einer Strategie zur Reward-Maximierung, unter der Berücksichtigung der bekannten Übergangswahrscheinlichkeiten und den erwarteten Rewards. 
Das ist auch der große Nachteil der Methodik, da diese Berechnungen sehr rechenaufwändig sind und ein perfektes Umgebungsmodell in den meisten Fällen nicht vorhanden ist.\\\\
Unter die nächste Kategorie fallen die Monte Carlo (MC) Methoden. 
Im Gegensatz zur Dynamischen Programmierung berechnen jene lediglich eine Schätzung der Wert-Funktion und finden aufgrund dessen die optimale Strategie. Außerdem benötigen diese auch kein Vorwissen über die Umgebung, sondern lernen durch die Interaktion mit der Umgebung, die Abfolge von Zuständen und Aktionen, sowie deren Rewards. Bei der Berechnung der Wertfunktion wird stets bis zum Ende einer Episode gewartet und eine Mittelung über alle erhaltenen Rewards durchgeführt. Dies funktioniert jedoch nur bei Problemstellungen, in denen Episoden auch terminieren. Sogleich ist das auch ein Nachteil der MC Methoden, da eine Bewertung eines Zustandes immer erst am Ende einer Episode realisiert werden kann.\\\\
Der letzte Ansatz wird als Temporal Difference (TD) Learning bezeichnet. 
Hierbei wird im Kontrast zu den MC Methoden nicht erst auf die Beendigung der Episode gewartet, sondern die Wertfunktion eines Zustandes gleich im nächsten Zeitschritt geschätzt. Diese Schätzungen basieren wiederum auf den bereits vorangegangene Schätzungen und nähern sich dadurch inkrementell dem \quotes{wahren} Wert der Wertfunktion an, ohne dabei wiederholt auf die Terminierung einer Episode warten zu müssen. \\
So ist auch bei dieser Art von Algorithmen kein Umgebungsmodell von Nöten, stattdessen werden die Bewertungen der Aktionen über die Zeit hinweg erörtert und gesammelt.